{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X): <class 'numpy.ndarray'>\n",
      "shape: (395, 4258)\n",
      "\n",
      "type(vocab): <class 'tuple'>\n",
      "len(vocab): 4258\n",
      "\n",
      "type(titles): <class 'tuple'>\n",
      "len(titles): 395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# document-term matrix\n",
    "X = lda.datasets.load_reuters()\n",
    "print(\"type(X): {}\".format(type(X)))\n",
    "print(\"shape: {}\\n\".format(X.shape))\n",
    "\n",
    "# the vocab\n",
    "vocab = lda.datasets.load_reuters_vocab()\n",
    "print(\"type(vocab): {}\".format(type(vocab)))\n",
    "print(\"len(vocab): {}\\n\".format(len(vocab)))\n",
    "\n",
    "# titles for each story\n",
    "titles = lda.datasets.load_reuters_titles()\n",
    "print(\"type(titles): {}\".format(type(titles)))\n",
    "print(\"len(titles): {}\\n\".format(len(titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x114062400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=20, n_iter=500, random_state=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(topic_word): <class 'numpy.ndarray'>\n",
      "shape: (20, 4258)\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_\n",
    "print(\"type(topic_word): {}\".format(type(topic_word)))\n",
    "print(\"shape: {}\".format(topic_word.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Topic 0\n",
      "- government british minister west group\n",
      "*Topic 1\n",
      "- church first during people political\n",
      "*Topic 2\n",
      "- elvis king wright fans presley\n",
      "*Topic 3\n",
      "- yeltsin russian russia president kremlin\n",
      "*Topic 4\n",
      "- pope vatican paul surgery pontiff\n",
      "*Topic 5\n",
      "- family police miami versace cunanan\n",
      "*Topic 6\n",
      "- south simpson born york white\n",
      "*Topic 7\n",
      "- order church mother successor since\n",
      "*Topic 8\n",
      "- charles prince diana royal queen\n",
      "*Topic 9\n",
      "- film france french against actor\n",
      "*Topic 10\n",
      "- germany german war nazi christian\n",
      "*Topic 11\n",
      "- east prize peace timor quebec\n",
      "*Topic 12\n",
      "- n't told life people church\n",
      "*Topic 13\n",
      "- years world time year last\n",
      "*Topic 14\n",
      "- mother teresa heart charity calcutta\n",
      "*Topic 15\n",
      "- city salonika exhibition buddhist byzantine\n",
      "*Topic 16\n",
      "- music first people tour including\n",
      "*Topic 17\n",
      "- church catholic bernardin cardinal bishop\n",
      "*Topic 18\n",
      "- harriman clinton u.s churchill paris\n",
      "*Topic 19\n",
      "- century art million museum city\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n+1):-1]\n",
    "    print('*Topic {}\\n- {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.concat(pd.read_csv(f) for f in glob.glob('tweet_data/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy.random\n",
    "\n",
    "values = tweets.text.values\n",
    "numpy.random.shuffle(values)\n",
    "texts = values[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c = Counter(tok for text in texts for tok in text.split())\n",
    "# c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vocab = [w for w, n in c.most_common() if n > 20]\n",
    "# word_to_vocab = {w: i for i, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tweets.text.apply(lambda t: [word_to_vocab.get(word) for word in t.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'i', \"i'm\",\n",
    "    'a', 'an', 'the', 'this', 'that', 'it',\n",
    "    'for', 'of', 'by',\n",
    "    'on', 'in', 'at',\n",
    "    'and', 'or', 'not', 'if',\n",
    "    'is', \"isn't\", 'was', 'were', 'be', 'being', 'are',\n",
    "    'can', \"can't\",\n",
    "    'do', \"dont\", 'did', \"didn't\",\n",
    "    'to', 'from',\n",
    "    'so', 'as',\n",
    "    'have', 'had', \n",
    "    'me', 'my', 'mine',\n",
    "    'you', 'your', 'yours', \n",
    "    'he', 'his',\n",
    "    'her', 'hers',\n",
    "    'we', 'our', 'ours', 'us',\n",
    "    'they', 'their', 'theirs',\n",
    "    'with',\n",
    "    'will',\n",
    "    'here', 'there',\n",
    "    'who', 'what', 'why', 'where', 'when', 'how',\n",
    "    'rt', 're', '&amp;', '-', '.', ',', '@', 'â€¦', '4', '...',\n",
    "\n",
    "    'too',\n",
    "    'no',\n",
    "    'but',\n",
    "    'up', 'down',\n",
    "    'in', 'out',\n",
    "    'like'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=10, stop_words=stop_words, tokenizer=str.split)\n",
    "X = cv.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x2183e41d0>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=25, n_iter=500, random_state=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Topic 0\n",
      "- labor has just been now vote bill greens all party\n",
      "*Topic 1\n",
      "- via trade #auspol australian | farmers free good piece australia\n",
      "*Topic 2\n",
      "- #auspol health into media senate today report inquiry education national\n",
      "*Topic 3\n",
      "- #auspol #politas labor energy #ausvotes #myliberal ^staff greens about state\n",
      "*Topic 4\n",
      "- more than better make people get pay much go less\n",
      "*Topic 5\n",
      "- great looking forward morning day thanks beautiful local today come\n",
      "*Topic 6\n",
      "- labor has budget #auspol under labor's more debt tax government\n",
      "*Topic 7\n",
      "- great school students congratulations year community new st today awards\n",
      "*Topic 8\n",
      "- go off good back time first one into great get\n",
      "*Topic 9\n",
      "- minister #auspol defence @juliebishopmp prime australian australia foreign meeting new\n",
      "*Topic 10\n",
      "- day great australian service world congratulations new anzac today australia\n",
      "*Topic 11\n",
      "- don't know about just get think it's would should want\n",
      "*Topic 12\n",
      "- road mp nsw today west coast great western member local\n",
      "*Topic 13\n",
      "- great thanks today forum good support see about meet local\n",
      "*Topic 14\n",
      "- jobs #auspol plan future new economic australian industry about growth\n",
      "*Topic 15\n",
      "- years has over been after 3 2 1 one year\n",
      "*Topic 16\n",
      "- #auspol labor climate change #ausvotes has bill government shorten people\n",
      "*Topic 17\n",
      "- against women people support violence help children national need aboriginal\n",
      "*Topic 18\n",
      "- all very happy thank thanks those family day best good\n",
      "*Topic 19\n",
      "- #auspol abbott #qt turnbull tony about malcolm has pm says\n",
      "*Topic 20\n",
      "- tax #auspol cuts abbott carbon cut health budget govt funding\n",
      "*Topic 21\n",
      "- well thanks done good great all @rharris334 very @darrenchestermp @grahamperrettmp\n",
      "*Topic 22\n",
      "- new speech read here: just #auspol facebook check photo today\n",
      "*Topic 23\n",
      "- about #auspol talking speaking live talk abc spoke morning interview\n",
      "*Topic 24\n",
      "- business small new local support funding great more centre care\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_\n",
    "n = 10\n",
    "vocab = np.array(cv.get_feature_names())\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = vocab[np.argsort(topic_dist)][:-(n+1):-1]\n",
    "    print('*Topic {}\\n- {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py3]",
   "language": "python",
   "name": "Python [py3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
